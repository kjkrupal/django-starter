## Initial Setup

We're adding the following to our application:

- Elasticsearch (v7.5.0)
- Elasticsearch DSL (v7.1.0)
- Python Elasticsearch Client (v7.1.0)

### Prerequisites

Before getting started, you **must** set your Docker Engine's Memory to **at least** 4 GiB. If you're using Docker Desktop for Mac, then you can change this setting from the toolbar. Select **Preferences...** and then click **Advanced**. From that screen, you can change the memory as shown below.

![Docker Desktop](/images/03_docker_desktop.png)

You also must change the `vm.max_map_count` to at least `262144`. Again, if you're on a Mac, run the following command in yout terminal:

```sh
$ screen ~/Library/Containers/com.docker.docker/Data/vms/0/tty
```

This will open a blank screen. Press `RETURN` on your keyboard and enter the following command:

```
sysctl -w vm.max_map_count=262144
```

Press `RETURN` again and then type `CTRL+A` and then `D` to exit the terminal.

If you need more help, check out the [Elasticsearch Docker installation guide](https://www.elastic.co/guide/en/elasticsearch/reference/current/docker.html).

### Connecting the Server to Elasticsearch

Let's start by adding a new `elasticsearch` service to our *docker-compose.yml* file:

```yml
# docker-compose.yml

version: '3.7'

services:
  database:
    container_name: perusable-database
    image: postgres:12.1
    ports:
      - 5433:5432
    volumes:
      - perusable-database:/var/lib/postgresql/data

  elasticsearch: # new
    container_name: perusable-elasticsearch
    environment:
      - ES_JAVA_OPTS=-Xms2g -Xmx2g
      - bootstrap.memory_lock=true
      - discovery.type=single-node
    image: elasticsearch:7.5.0
    ports:
      - 9201:9200
    volumes:
      - perusable-elasticsearch:/usr/share/elasticsearch/data

  server:
    build:
      context: ./server
    container_name: perusable-server
    command: [ "bash", "start.sh" ]
    depends_on:
      - database
      - elasticsearch # new
    environment:
      - PGDATABASE=perusable
      - PGUSER=perusable
      - PGPASSWORD=perusable
      - PGHOST=perusable-database
      - ES_HOSTS=http://perusable-elasticsearch:9200 # new
    ports:
      - 8001:8000
    volumes:
      - ./server:/usr/src/app
      - static:/usr/src/app/static

  client:
    build:
      context: ./client
    command: [ "npm", "start" ]
    container_name: perusable-client
    depends_on:
      - server
    ports:
      - 3001:3000

  reverse-proxy:
    build:
      context: ./reverse-proxy
    container_name: perusable-reverse-proxy
    depends_on:
      - server
      - client
    ports:
      - 8080:80
    restart: always
    volumes:
      - static:/usr/src/app/static

volumes:
  perusable-database:
  perusable-elasticsearch: # new
  static:
```

Take note of the fact that we're updating our `server` service to depend on `elasticsearch`. We're also passing in a new `ES_HOSTS` environment variable that tells the server how to connect to Elasticsearch. Elasticsearch runs on remote port `9200`. We're adding a new volume too, which holds the Elasticsearch [indexes](https://www.elastic.co/blog/what-is-an-elasticsearch-index). Indexes are like databases -- they store all of the data that we want to search.

> **NOTE**
> 
> If you didn't read the [Elasticsearch Docker installation guide](https://www.elastic.co/guide/en/elasticsearch/reference/current/docker.html), here's what the environment variables we are passing to our Elasticsearch service mean:
> 
> |Variable|Meaning|More Information|
> |--------|-------|----------------|
> | `ES_JAVA_OPTS=-Xms2g -Xmx2g` | Set the minimum and maximum heap size to 2 GB | [Setting the heap size](https://www.elastic.co/guide/en/elasticsearch/reference/current/heap-size.html) |
> | `bootstrap.memory_lock=true` | Disable swapping memory to disk | [Memory lock check](https://www.elastic.co/guide/en/elasticsearch/reference/master/_memory_lock_check.html) |
> | `discovery.type=single-node` | Use a single node (for local development) | [Single-node discovery](https://www.elastic.co/guide/en/elasticsearch/reference/current/bootstrap-checks.html#single-node-discovery) |

Let's add the [Elasticsearch DSL](https://elasticsearch-dsl.readthedocs.io/en/latest/) library to our Python dependencies to facilitate communication between Django and Elasticsearch.

```conf
# server/requirements.txt

Django==3.0.1
django-debug-toolbar==2.1
django-filter==2.2.0
djangorestframework==3.11.0
elasticsearch-dsl==7.1.0 # new
gunicorn==20.0.4
psycopg2-binary==2.8.4
```

Open your terminal and refresh the Docker containers.

```
$ docker-compose up -d --build
```

Once the containers are up and running, hit the Elasticsearch service via its HTTP endpoint. (Look back at the *docker-compose.yml* file to confirm that the port is mapped to `9201` on your host machine.)

```
$ curl "http://localhost:9201"
```

You should see something like the following get returned:

```
{
  "name" : "afce149cf127",
  "cluster_name" : "docker-cluster",
  "cluster_uuid" : "w55wZG2aSrelt7Y5CA728A",
  "version" : {
    "number" : "7.5.0",
    "build_flavor" : "default",
    "build_type" : "docker",
    "build_hash" : "e9ccaed468e2fac2275a3761849cbee64b39519f",
    "build_date" : "2019-11-26T01:06:52.518245Z",
    "build_snapshot" : false,
    "lucene_version" : "8.3.0",
    "minimum_wire_compatibility_version" : "6.8.0",
    "minimum_index_compatibility_version" : "6.0.0-beta1"
  },
  "tagline" : "You Know, for Search"
}
```

Now that we've confirmed that the Elasticsearch service is running, let's update our Django settings file to hook the server to Elasticsearch.

```python
# server/perusable/perusable/settings.py

def get_env_list(key, default=None): # new
    env = os.getenv(key)
    if env:
        return env.split(',')
    return default


ES_HOSTS = get_env_list('ES_HOSTS', ['http://localhost:9200']) # new

ES_CONNECTION = connections.create_connection(hosts=ES_HOSTS) # new
```

Add the following import to the top of the settings page too:

```python
# server/perusable/perusable/settings.py

from elasticsearch_dsl import connections
```
