## Building an Elasticsearch Index

Let's create an Elasticsearch index. We'll write a Django management command to create the index, and then we'll confirm its existence with the Elasticsearch API.

From the project's root directory, create a new management commands folder.

```
$ mkdir -p server/perusable/catalog/management/commands
```

In order to make the *management* and *commands* directories show up in the Python path, we need to add *\_\_init\_\_.py* files.

```
$ touch server/perusable/catalog/management/__init__.py
$ touch server/perusable/catalog/management/commands/__init__.py
```

Create a new *create_index.py* file in the *commands* directory with the following code.

```python
# server/perusable/catalog/management/commands/create_index.py

from django.core.management.base import BaseCommand

from elasticsearch_dsl import connections


class Command(BaseCommand):
    help = 'Creates an Elasticsearch index.'

    def handle(self, *args, **kwargs):
        index = 'wine'
        self.stdout.write(f'Creating index "{index}"...')
        connection = connections.get_connection()
        if connection.indices.exists(index=index):
            self.stdout.write(f'Index "{index}" already exists')
        else:
            connection.indices.create(index=index, body={
                'settings': {
                    'number_of_shards': 1,
                    'number_of_replicas': 0,
                }
            })
            self.stdout.write(f'Index "{index}" created successfully')
```

We're using the new `elasticsearch_dsl` library. First, we initialize a connection with the Elasticsearch service. Then, check if an index with the name "wine" already exists. Index names are unique. If the index already exists, then we tell the user. If it does not exist, then we create it. We initialize our new index with the barest settings -- a single shard to hold the entire index with no replicas (backups). These settings are sufficient for development, but choosing production settings is a [bigger deal](https://www.elastic.co/blog/how-many-shards-should-i-have-in-my-elasticsearch-cluster).

> The code you just wrote defines a Django management command and makes it available through *manage.py*. Run the following line in your terminal.
>
> ```
> $ docker-compose exec server python /usr/src/app/perusable/manage.py
> ```
>
> You should see a list of all the available management commands for your app. Find the header labelled `[catalog]` and locate your new command.

Run the new command to create a "wine" index.

```
$ docker-compose exec server python /usr/src/app/perusable/manage.py create_index
```

You should see the following print to your terminal.

```
Creating index "wine"...
Index "wine" created successfully
```

Confirm that the index exists using the following command. (An HTTP 200 OK status means it exists.)

```
$ curl --head "http://localhost:9201/wine"
```

If you want to see a little more about your index, then try the following command instead.

```
$ curl "http://localhost:9201/wine/_settings?pretty"
```

Your results will look a little different based on your local date and time and machine.

```
{
  "wine" : {
    "settings" : {
      "index" : {
        "number_of_shards" : "1",
        "provided_name" : "wine",
        "creation_date" : "1577152626254",
        "number_of_replicas" : "0",
        "uuid" : "7H_-wq1TTmq5CiY1GTLFBg",
        "version" : {
          "created" : "7050099"
        }
      }
    }
  }
}
```

Next, we need to add a mapping to our index. A mapping is like a schema in Postgres -- it defines the fields that the document supports. We define each field in an Elasticsearch mapping with a name and a type. Elasticsearch defines two different string datatypes: [text](https://www.elastic.co/guide/en/elasticsearch/reference/7.5/text.html) and [keyword](https://www.elastic.co/guide/en/elasticsearch/reference/7.5/keyword.html). The `text` datatype tells Elasticsearch to index the values for full text search. The `keyword` datatype tells Elasticsearch to only use the value for exact matches. Both come in handy in different situations.

One interesting difference between the way Postgres and Elasticsearch handle full text search is that Elasticsearch does not use an English analyzer by default. Run the following code in your terminal to use the default analyzer on an example winery.

```
$ curl "http://localhost:9201/_analyze?pretty" -H "Content-Type: application/json" -d '
{
  "text": "succulent on the close"
}
'
```

The Elasticsearch analyzer breaks the text into tokens and provides similar information to PostgreSQL's `to_tsvector()` function.

```
{
  "tokens" : [
    {
      "token" : "succulent",
      "start_offset" : 0,
      "end_offset" : 9,
      "type" : "<ALPHANUM>",
      "position" : 0
    },
    {
      "token" : "on",
      "start_offset" : 10,
      "end_offset" : 12,
      "type" : "<ALPHANUM>",
      "position" : 1
    },
    {
      "token" : "the",
      "start_offset" : 13,
      "end_offset" : 16,
      "type" : "<ALPHANUM>",
      "position" : 2
    },
    {
      "token" : "close",
      "start_offset" : 17,
      "end_offset" : 22,
      "type" : "<ALPHANUM>",
      "position" : 3
    }
  ]
}
```

As you can see, the standard analyzer just breaks the text into words by removing whitespace and converting all characters to lowercase.

If we want to use the English analyzer, then we have to explicitly declare it. Compare the tokens in the previous command to the ones that are created with the following command.

```
$ curl "http://localhost:9201/_analyze?pretty" -H "Content-Type: application/json" -d '
{
  "text": "succulent on the close",
  "analyzer": "english"
}
'
```

The output is exactly what we're looking for.

```
{
  "tokens" : [
    {
      "token" : "succul",
      "start_offset" : 0,
      "end_offset" : 9,
      "type" : "<ALPHANUM>",
      "position" : 0
    },
    {
      "token" : "close",
      "start_offset" : 17,
      "end_offset" : 22,
      "type" : "<ALPHANUM>",
      "position" : 3
    }
  ]
}
```

The stop words, "on" and "the", are removed as is the whitespace. The remaining words are stemmed using an English dictionary and the characters are converted to lowercase.

Let's create a new `update_mapping` Django management command to add a mapping to our "wine" index.

```python
# server/perusable/catalog/management/commands/update_mapping.py

from django.core.management.base import BaseCommand, CommandError

from elasticsearch_dsl import connections


class Command(BaseCommand):
    help = 'Updates a mapping on an Elasticsearch index.'

    def handle(self, *args, **kwargs):
        index = 'wine'
        self.stdout.write(f'Updating mapping on "{index}" index...')
        connection = connections.get_connection()
        if connection.indices.exists(index=index):
            connection.indices.put_mapping(index=index, body={
                'properties': {
                    'variety': {
                        'type': 'text',
                        'analyzer': 'english',
                    },
                    'winery': {
                        'type': 'text',
                        'analyzer': 'english',
                    },
                    'description': {
                        'type': 'text',
                        'analyzer': 'english',
                    }
                }
            })
            self.stdout.write(f'Updated mapping on "{index}" successfully')
        else:
            raise CommandError(f'Index "{index}" does not exist')
```

This time we use the `elasticsearch` library's `put_mapping()` function. We define a "wine" document to have three properties -- `variety`, `winery`, and `description`. We'll add the remaining fields later in the tutorial.

Run the command to add the mapping.

```
$ docker-compose exec server python /usr/src/app/perusable/manage.py update_mapping
```

You should see the following text write to your terminal.

```
Updating mapping on "wine" index...
Updated mapping on "wine" successfully
```

How does it look on Elasticsearch? Run the following `cURL` command to find out.

```
$ curl "http://localhost:9201/wine/_mapping?pretty"
```

You should see the following response from Elasticsearch.

```
{
  "wine" : {
    "mappings" : {
      "properties" : {
        "description" : {
          "type" : "text",
          "analyzer" : "english"
        },
        "variety" : {
          "type" : "text",
          "analyzer" : "english"
        },
        "winery" : {
          "type" : "text",
          "analyzer" : "english"
        }
      }
    }
  }
}
```

Now, we have a "wine" index that defines a "wine" document. The only thing we're missing is actual data. Write a new `bulk_update` management command to populate our index as shown below.

```python
# server/perusable/catalog/management/commands/bulk_update.py

from django.core.management.base import BaseCommand

from elasticsearch_dsl import connections
from elasticsearch.helpers import bulk

from catalog.models import Wine


class Command(BaseCommand):
    help = 'Updates the Elasticsearch index.'

    def _document_generator(self):
        for wine in Wine.objects.iterator():
            yield {
                '_index': 'wine',
                '_id': wine.id,
                'variety': wine.variety,
                'winery': wine.winery,
                'description': wine.description,
            }

    def handle(self, *args, **kwargs):
        index = 'wine'
        self.stdout.write(f'Bulk updating documents on "{index}" index...')
        connection = connections.get_connection()
        succeeded, _ = bulk(connection, actions=self._document_generator(), stats_only=True)
        self.stdout.write(f'Updated {succeeded} documents on "{index}" successfully')
```

Our new management command takes advantage of Elasticsearch's [bulk API](https://www.elastic.co/guide/en/elasticsearch/reference/7.5/docs-bulk.html). Elasticsearch offers APIs to index documents one-by-one too, but when you need to update many documents at once, nothing beats the performance of the bulk API. Our code loads all (150,000+) of our `Wine` records from the Postgres database and writes them to Elasticsearch.

Run the following command to perform the transfer.

```
$ docker-compose exec server python /usr/src/app/perusable/manage.py bulk_update
```

You should see the following messages in your terminal after a few seconds. (This took about 30 seconds on my machine.)

```
Bulk updating documents on "wine" index...
Updated 150930 documents on "wine" successfully
```

How do we know the records are actually in Elasticsearch? Try this query to show the document count:

```
$ curl "http://localhost:9201/wine/_count?pretty"
```

You should see the following response in your terminal: 

```
{
  "count" : 150930,
  "_shards" : {
    "total" : 1,
    "successful" : 1,
    "skipped" : 0,
    "failed" : 0
  }
}
```

As we can see, the query confirmed there are 150,930 wine documents in the index.

Let's perform a search using `cURL` and then program it into our app. The following API will return all wine documents that match according to these parameters:
- `variety` matches the analyzed form of the word, "staglin", OR
- `winery` matches an analyzed form of the word, "staglin", OR
- `description` matches an analyzed form of the word, "staglin"

```
$ curl -X POST "http://localhost:9201/wine/_search?size=100&pretty" -H "Content-Type: application/json" -d '
{
  "query": {
    "bool": {
      "should": [
        {"match": {"variety": "staglin"}},
        {"match": {"winery": "staglin"}},
        {"match": {"description": "staglin"}}
      ]
    }
  }
}
'
```

As you can see below, the search is conducted extremely fast (38 milliseconds) and it finds 11 results that match the parameters.

```
{
  "took" : 38,
  "timed_out" : false,
  "_shards" : {
    "total" : 1,
    "successful" : 1,
    "skipped" : 0,
    "failed" : 0
  },
  "hits" : {
    "total" : {
      "value" : 11,
      "relation" : "eq"
    },
    "max_score" : 21.410278,
    "hits" : [
      ...
    ]
  }
}
```

Let's perform the same query in our app. Add a new `ESWinesView` class to our *views.py* file.

```python
# server/perusable/catalog/views.py

from django.conf import settings # new

from elasticsearch_dsl import Search # new
from elasticsearch_dsl.query import Match, Term # new
from rest_framework.generics import ListAPIView
from rest_framework.response import Response # new
from rest_framework.views import APIView # new

from .models import Wine, WineSearchWord
from .serializers import WineSerializer, WineSearchWordSerializer
from .filters import WineFilterSet, WineSearchWordFilterSet


class WinesView(ListAPIView):
    queryset = Wine.objects.all()
    serializer_class = WineSerializer
    filterset_class = WineFilterSet


class WineSearchWordsView(ListAPIView):
    queryset = WineSearchWord.objects.all()
    serializer_class = WineSearchWordSerializer
    filterset_class = WineSearchWordFilterSet


# new
class ESWinesView(APIView):
    def get(self, request, *args, **kwargs):
        query = self.request.query_params.get('query')

        # Build Elasticsearch query.
        search = Search()
        response = search.query('bool', should=[
            Match(variety=query),
            Match(winery=query),
            Match(description=query)
        ]).params(size=100).execute()

        if response.hits.total.value > 0:
            return Response(data=[{
                'variety': hit.variety,
                'country': hit.country,
                'price': hit.price,
                'winery': hit.winery,
                'description': hit.description,
                'points': hit.points,
            } for hit in response])
        else:
            return Response(data=[])
```

Notice we are using the most basic type of Django REST Framework view. We pluck the `query` query parameter from the incoming request and use it to build a compound [bool query](https://www.elastic.co/guide/en/elasticsearch/reference/7.5/query-dsl-bool-query.html). The `should` clause tells Elasticsearch to return results if any of the contained queries match a document. Contrast that with the `must` clause, which dictates that a match must contain all of the stated queries.

We're also passing in a limit of `size=100` with our request. At most, we want Elasticsearch to return 100 results. When we get a response, we manipulate it and pass the `_source` data directly to the client. An empty match will return an empty list.

Wire up the complementary URL as shown.

```python
# server/perusable/catalog/urls.py

from django.urls import path

from .views import WinesView, WineSearchWordsView, ESWinesView # changed

urlpatterns = [
    path('wines/', WinesView.as_view()),
    path('wine-search-words/', WineSearchWordsView.as_view()),
    path('es-wines/', ESWinesView.as_view()), # new
]
```

Hit the new API endpoint in your browser to test it.

[http://localhost:8080/api/v1/catalog/es-wines/?query=staglin](http://localhost:8080/api/v1/catalog/es-wines/?query=staglin)

Oops, we get an error because we haven't added `country` to our Elasticsearch index yet!

![attribute error country](/images/03_attribute_error_country.png)

So far we've hardcoded a lot of data in multiple files. Let's keep our code DRY and define some reusable constants. At the same time, we'll add the rest of our wine document fields.

```python
# server/perusable/catalog/constants.py

ES_INDEX = 'wine'

ES_MAPPING = {
    'dynamic': 'strict',
    'properties': {
        'variety': {
            'type': 'text',
            'analyzer': 'english',
        },
        'country': {
            'type': 'keyword',
        },
        'price': {
            'type': 'keyword',
        },
        'winery': {
            'type': 'text',
            'analyzer': 'english',
        },
        'description': {
            'type': 'text',
            'analyzer': 'english',
        },
        'points': {
            'type': 'float',
        }
    }
}
```

Refactor the `update_mapping` management command to use the new constants.

```python
# server/perusable/catalog/management/commands/update_mapping.py

from django.core.management.base import BaseCommand, CommandError

from elasticsearch_dsl import connections

from catalog.constants import ES_INDEX, ES_MAPPING # new


class Command(BaseCommand):
    help = 'Updates a mapping on an Elasticsearch index.'

    def handle(self, *args, **kwargs): # changed
        self.stdout.write(f'Updating mapping on "{ES_INDEX}" index...')
        connection = connections.get_connection()
        if connection.indices.exists(index=ES_INDEX):
            connection.indices.put_mapping(index=ES_INDEX, body=ES_MAPPING)
            self.stdout.write(f'Updated mapping on "{ES_INDEX}" successfully')
        else:
            raise CommandError(f'Index "{ES_INDEX}" does not exist')
```

Does everything still work? Run the `update_mapping` command to see for yourself. Don't worry -- only the new fields will be [added to the index](https://www.elastic.co/guide/en/elasticsearch/reference/7.5/indices-put-mapping.html).

```
$ docker-compose exec server python /usr/src/app/perusable/manage.py update_mapping
```

You should see the following messages print to your terminal.

```
Updating mapping on "wine" index...
Updated mapping on "wine" successfully
```

Next, let's update our `bulk_update` management command to use our constants and update our wine documents with the new fields.

```python
# server/perusable/catalog/management/commands/bulk_update.py

from django.core.management.base import BaseCommand

from elasticsearch_dsl import connections
from elasticsearch.helpers import bulk

from catalog.constants import ES_INDEX # new
from catalog.models import Wine


class Command(BaseCommand):
    help = 'Updates the Elasticsearch index.'

    # changed
    def _document_generator(self):
        for wine in Wine.objects.iterator():
            yield {
                '_index': ES_INDEX,
                '_id': wine.id,
                'variety': wine.variety,
                'country': wine.country,
                'price': wine.price,
                'winery': wine.winery,
                'description': wine.description,
                'points': wine.points,
            }

    # changed
    def handle(self, *args, **kwargs):
        self.stdout.write(f'Bulk updating documents on "{ES_INDEX}" index...')
        connection = connections.get_connection()
        succeeded, _ = bulk(connection, actions=self._document_generator(), stats_only=True)
        self.stdout.write(f'Updated {succeeded} documents on "{ES_INDEX}" successfully')
```

Execute the update with the following command.

```
$ docker-compose exec server python /usr/src/app/perusable/manage.py bulk_update
```

All 150,930 records are updated. That means each document now has the data for the new fields as well as the old ones.

```
Bulk updating documents on "wine" index...
Updated 150930 documents on "wine" successfully
```

Visit [http://localhost:8080/api/v1/catalog/es-wines/?query=staglin](http://localhost:8080/api/v1/catalog/es-wines/?query=staglin) again to confirm that it works now.

![Elasticsearch wines API](/images/03_elasticsearch_wines_api.png)

How do we support the `country` and `points` filters that we added in the previous part? We add them as filters to our compound query. Try the following `cURL` command in your terminal.

```
$ curl -X POST "http://localhost:9201/wine/_search?size=100&pretty" -H "Content-Type: application/json" -d '
{
  "query": {
    "bool": {
      "should": [
        {"match": {"variety": "staglin"}},
        {"match": {"winery": "staglin"}},
        {"match": {"description": "staglin"}}
      ],
      "filter": [
        {"term": {"country": "US"}},
        {"term": {"points": 94}}
      ]
    }
  }
}
'
```

Hold on a second, look at the result below. How did we get 1,724 results? Shouldn't filtering limit the number of results we get back, not increase it?

```
{
  "took" : 51,
  "timed_out" : false,
  "_shards" : {
    "total" : 1,
    "successful" : 1,
    "skipped" : 0,
    "failed" : 0
  },
  "hits" : {
    "total" : {
      "value" : 1724,
      "relation" : "eq"
    },
    "max_score" : 0.0,
    "hits" : [
      ...
    ]
  }
}
```

Let's take another look at the `should` section of the [bool query](https://www.elastic.co/guide/en/elasticsearch/reference/7.5/query-dsl-bool-query.html) documentation.

> The clause (query) should appear in the matching document. **If the `bool` query is in a query context and has a `must` or `filter` clause then a document will match the `bool` query even if none of the `should` queries match.** In this case these clauses are only used to influence the score. If the `bool` query is a filter context or has neither `must` or `filter` then at least one of the `should` queries must match a document for it to match the `bool` query. This behavior may be explicitly controlled by setting the `minimum_should_match parameter`.

Looks like we need to specify a value for `minimum_should_match` in our query. Let's add it and run the query again.

```
$ curl -X POST "http://localhost:9201/wine/_search?size=100&pretty" -H "Content-Type: application/json" -d '
{
  "query": {
    "bool": {
      "should": [
        {"match": {"variety": "staglin"}},
        {"match": {"winery": "staglin"}},
        {"match": {"description": "staglin"}}
      ],
      "filter": [
        {"term": {"country": "US"}},
        {"term": {"points": 94}}
      ],
      "minimum_should_match": 1
    }
  }
}
'
```

You should get the following result: 

```
{
  "took" : 6,
  "timed_out" : false,
  "_shards" : {
    "total" : 1,
    "successful" : 1,
    "skipped" : 0,
    "failed" : 0
  },
  "hits" : {
    "total" : {
      "value" : 1,
      "relation" : "eq"
    },
    "max_score" : 19.370035,
    "hits" : [
      ...
    ]
  }
}
```

That one match makes a lot more sense. Only one Staglin wine has a score of 94. Confirm that the filtered result is correct by examining the result of the query without filters. Did the filters work the way you'd expect?

Let's update our API function to use our new query.

```python
# server/perusable/catalog/views.py

class ESWinesView(APIView):
    def get(self, request, *args, **kwargs):
        query = self.request.query_params.get('query')
        country = self.request.query_params.get('country')
        points = self.request.query_params.get('points')

        # Build Elasticsearch query.
        search = Search()
        response = search.query('bool', should=[
            Match(variety=query),
            Match(winery=query),
            Match(description=query)
        ], filter=[
            Term(country=country),
            Term(points=points)
        ], minimum_should_match=1).params(size=100).execute()

        if response.hits.total.value > 0:
            return Response(data=[{
                'variety': hit.variety,
                'country': hit.country,
                'price': hit.price,
                'winery': hit.winery,
                'description': hit.description,
                'points': hit.points,
            } for hit in response])
        else:
            return Response(data=[])
```

Test the API in your browser with more query parameters.

[http://localhost:8080/api/v1/catalog/es-wines/?query=staglin&country=US&points=94](http://localhost:8080/api/v1/catalog/es-wines/?query=staglin&country=US&points=94)

Before we move on, let's do a little refactoring. Why have three separate management commands when one can suffice? Let's merge all of the functionality into a new `elasticsearch` Django management command.

```python
# server/perusable/catalog/management/commands/elasticsearch.py

from django.core.management.base import BaseCommand

from elasticsearch_dsl import connections
from elasticsearch.helpers import bulk

from catalog.constants import ES_INDEX, ES_MAPPING
from catalog.models import Wine


class Command(BaseCommand):
    help = 'Updates the Elasticsearch index.'

    def _document_generator(self):
        for wine in Wine.objects.iterator():
            yield {
                '_index': ES_INDEX,
                '_id': wine.id,
                'variety': wine.variety,
                'country': wine.country,
                'price': wine.price,
                'winery': wine.winery,
                'description': wine.description,
                'points': wine.points,
            }

    def handle(self, *args, **kwargs):
        connection = connections.get_connection()

        self.stdout.write(f'Checking if index "{ES_INDEX}" exists...')
        if connection.indices.exists(index=ES_INDEX):
            self.stdout.write(f'Index "{ES_INDEX}" already exists')
            self.stdout.write(f'Updating mapping on "{ES_INDEX}" index...')
            connection.indices.put_mapping(index=ES_INDEX, body=ES_MAPPING)
            self.stdout.write(f'Updated mapping on "{ES_INDEX}" successfully')
        else:
            self.stdout.write(f'Index "{ES_INDEX}" does not exist')
            self.stdout.write(f'Creating index "{ES_INDEX}"...')
            connection.indices.create(index=ES_INDEX, body={
                'settings': {
                    'number_of_shards': 1,
                    'number_of_replicas': 0,
                },
                'mappings': ES_MAPPING,
            })
            self.stdout.write(f'Index "{ES_INDEX}" created successfully')

        self.stdout.write(f'Bulk updating documents on "{ES_INDEX}" index...')
        succeeded, _ = bulk(connection, actions=self._document_generator(), stats_only=True)
        self.stdout.write(f'Updated {succeeded} documents on "{ES_INDEX}" successfully')
```

The new code shouldn't look foreign to you. We literally merged the functionality of the previous three commands into one. We added some conditional logic to create an index if it doesn't exist, update the mapping, and update the wine documents from our primary data store.

We can remove the old commands too.

```
$ rm server/perusable/catalog/management/commands/bulk_update.py
$ rm server/perusable/catalog/management/commands/create_index.py
$ rm server/perusable/catalog/management/commands/update_mapping.py
```

Currently, our `ESWinesView` API assumes that every query parameter will be supplied by the user. We know that the client optionally passes parameters with the HTTP request. Let's refactor the view to conditionally handle the parameters.

```python
# server/perusable/catalog/views.py

class ESWinesView(APIView):
    def get(self, request, *args, **kwargs):
        query = self.request.query_params.get('query')
        country = self.request.query_params.get('country')
        points = self.request.query_params.get('points')

        # Build Elasticsearch query.
        search = Search()
        q = {'should': [], 'filter': []}

        # Build should clause.
        if query:
            q['should'] = [
                Match(variety=query),
                Match(winery=query),
                Match(description=query)
            ]
            q['minimum_should_match'] = 1

        # Build filter clause.
        if country:
            q['filter'].append(Term(country=country))
        if points:
            q['filter'].append(Term(points=points))

        response = search.query('bool', **q).params(size=100).execute()

        if response.hits.total.value > 0:
            return Response(data=[{
                'variety': hit.variety,
                'country': hit.country,
                'price': hit.price,
                'winery': hit.winery,
                'description': hit.description,
                'points': hit.points,
            } for hit in response])
        else:
            return Response(data=[])
```

In the code above, we separated the query-building logic into two functions -- one to build the `should` clause and the other to build the `filter` clause. The results are only used if the parameters are present in the incoming HTTP request.
